##前端集成解决方案
###什么是前端集成解决方案？
前端集成解决方案，英文翻译为 Front-end Integrated Solution，缩写fis，发音[fɪs]

将这个词拆开来看，我们能得到：
- 前端：指前端领域，即web研发中常用的浏览器客户端相关技术，比如html、js、css等
- 集成：将一些孤立的事物或元素通过某种方式改变原有的分散状态集中在一起，产生联系，从而构成一个有机整体的过程。
- 解决方案：针对某些已经体现出的，或者可以预期的问题，不足，缺陷，需求等等，所提出的一个解决问题的方案，同时能够确保加以有效的执行。

总结来说，前端集成解决方案就是：   
`将前端研发领域中各种分散的技术元素集中在一起，并对常见的前端开发问题、不足、缺陷和需求，所提出的一种解决问题的方案。`
###前端领域有哪些技术元素
![](./image/前端领域有哪些技术元素.png)

1. **开发规范**：包括开发、部署的目录规范，编码规范等。不要小瞧规范的威力，可以极大的提升开发效率，真正优秀的规范不会让使用者感到约束，而是能帮助他们快速定位问题，提升效率。
- **模块化开发**：针对js、css，以功能或业务为单元组织代码。js方面解决独立作用域、依赖管理、api暴露、按需加载与执行、安全合并等问题，css方面解决依赖管理、组件内部样式管理等问题。是提升前端开发效率的重要基础。现在流行的模块化框架有requirejs、seajs等。
- **组件化开发**：在模块化基础上，以页面小部件(component)为单位将页面小部件的js、css、html代码片段放在一起进行开发、维护，组件单元是资源独立的，组件在系统内可复用。比如头部(header)、尾部(footer)、搜索框(searchbar)、导航(menu)、对话框(dialog)等，甚至一些复杂的组件比如编辑器(editor)等。通常业务会针对组件化的js部分进行必要的封装，解决一些常见的组件渲染、交互问题。
- **组件仓库**：有了组件化，我们希望将一些非常通用的组件放到一个公共的地方供团队共享，方便新项目复用，这个时候我们就需要引入一个组件仓库的东西，现在流行的组件库有bower、component等。团队发展到一定规模后，组件库的需求会变得非常强烈。
- **性能优化**：这里的性能优化是指能够通过工程手段保证的性能优化点。性能优化是前端项目发展到一定阶段必须经历的过程。这部分我想强调的一点是**性能优化一定是一个工程问题和统计问题**，不能用工程手段保证的性能优化是不靠谱的，优化时只考虑一个页面的首次加载，不考虑全局在宏观统计上的优化提升也是片面的。
- **项目部署**：部署按照现行业界的分工标准，虽然不是前端的工作范畴，但它对性能优化有直接的影响，包括静态资源缓存、cdn、非覆盖式发布等问题。合理的静态资源资源部署可以为前端性能带来较大的优化空间。
- **开发流程**：完整的开发流程包括本地开发调试、视觉效果走查确认、前后端联调、提测、上线等环节。对开发流程的改善可以大幅降低开发的时间成本，工作这些年见过很多独立的系统（cms系统、静态资源推送系统）将开发流程割裂开，对前端开发的效率有严重的阻碍。
- **开发工具**：这里说的工具不是指IDE，而是工程工具，包括构建与优化工具、开发-调试-部署等流程工具，以及组件库获取、提交等相关工具，甚至运营、文档、配置发布等平台工具。前端开发需要工具支持，这个问题的根本原因来自前端领域语言特性。前端开发所使用的语言（js、css、html）以及前端工程资源的加载与定位策略决定了前端工程必须要工具支持。由于这些工具通常都是独立的系统，要想把它们串联起来，才有了yeoman这样的封装。前面提到的7项技术元素都直接或间接的对前端开发工具设计产生一定的影响，因此能否串联其他技术要素，使得前端开发形成一个连贯可持续优化的开发体系，工具的设计至关重要。

以上8项，1-3是技术和业务相关的开发需求，4是技术沉淀与共享需求，5-8是工程优化需求。

经过这些年的工程领域实践，个人觉得以上8项技术元素应该成为绝大多数具有一定规模的前端开发团队的标配。

###攒一套前端集成解决方案
正如前面的贴图展示的那样，所有的技术点都有一定的内在联系：

- 模块化开发涉及到性能优化、对构建工具又有一定的配套实现要求，也会影响开发规范的定制
- 组件化开发应该基于模块化框架来加载其他依赖的组件，如果组件化框架自带模块管理功能，那么就可能导致工程性的性能优化实现困难
- 组件库应该与组件化开发配套，组件仓库中的组件都应该按照相同的标准来实现，否则下载的组件不具有可复用性、可移植性，就是去了仓库的意义
- 我们设计的开发规范工具是否能很容易的实现，如果部署上有特殊要求，工具是否能很容易的做出调整，而不是修改规范。
- 工具是否能提供接入公司已有流程中的接口，比如命令调用，如果工具需要一些系统环境支持，公司的ci流程中是否能支持等问题。

前端领域语言的特点决定了攒一套集成解决方案有很高的实现成本。因为前端语言缺少包、导入、模块等开发概念，这使得各个技术点的解决方案在设计的时候都是考虑**被独立使用的情况下如何工作**，因此或多或少的会延伸自己的职责。比如模块化框架要附属构建工具，甚至要求后端服务（比如combo），组件化框架自带模块化框架，构建工具自带部署规范等，这就大大提高了将各个技术要素融合起来的成本。

总之，前述的8项技术要素之间有许多联系，这就为打造一套完整连贯的前端集成解决方案带来了较大的挑战。如何兼顾规范、性能、框架、流程、部署等问题，就不是东拼西凑那么简单的事了。
###关于前端工程的核心问题
前端工程只有两个核心问题：
**一个是 资源定位，另一个是 模块化开发。**

![](./image/前端工程的核心问题.png)

前端工程的所有工作都是围绕着这两个核心问题展开的。资源定位的主要思想就是将 工程路径 转换为 部署路径，也就是把相对路径变成绝对路径并且加上md5戳和域名。这样做的目的是解决静态资源缓存更新的问题，同时为模块化开发这个问题做准备。因为只有将所有相对路径转换成绝对路径才能实现模块的独立性，模块才能被任何地方使用都不用担心里面资源加载的问题。你所喜欢的内嵌功能，也是要建立在路径转换的基础上，因为内嵌会改变路径关系，绝对化处理可以让任意文件间的内嵌成为可能。

模块化开发呢，在解决了资源定位的前提下，核心问题就是依赖管理和加载了。**尽量依靠框架实现，最少依赖构建工具处理。** 就是说，尽量不要让构建工具做太多事情，因为那很黑盒，构建工具只负责生成依赖关系表，这就足够了，然后框架自己决定什么时候该加载哪些资源，表的关系可以让框架加载时完成按需、请求合并等需求。 


###讨论
补充：

1. 关于组件化和模块化，这个粒度实在是不好拿捏，模块可以很大，也可以很小，小到一个函数成一个模块，所以我觉得模块应该主要是通用工具、api、类的封装，而组件更多的是业务功能、UI块的封装
2. 关于组件仓库，其实bower、component之类的并不够，还有文档的生成与管理，使用别人写的代码，最快入手的就是看文档，其次才是看代码
3. 还有，测试。纯工具和api之类的模块，很容易自动化测试，蛋是到了组件层面，设计业务逻辑、UI什么的，自动化太难了，还得靠人肉.

本文只是列出了一些技术要素，介绍前端工程中的基本概念。模块粒度、组件划分、仓库建设以及测试是要各个方向展开来说明。

前端工程可以在 前端开发，性能优化，持续集成，自动部署、模块生态、甚至 CMS运营系统 中都能发挥功效。

模块化框架和工具做好了之后，就在模块化框架里做性能优化，比如请求合并、按需加载、localstorage缓存（移动端）等，然后就是开发过程和持续集成与部署结合，内网搭建jenkins，提交即构建，构建结果存放到代码仓库 ，然后实现部署推送。接下来将历往项目中的通用模块抽取出来，放到生态里，比如GitHub上，然后在开发工具中集成一个install的小工具，用于项目初期获取这些模块，可以进一步提高效率。

问题：   
因为只有将所有相对路径转换成绝对路径才能实现模块的独立性，模块才能被任何地方使用都不用担心里面资源加载的问题。组件或者模块内部为什么要把相对路径转化成绝对路径呢？对于独立的模块，不依赖与其他模块，对于这个模块的一些资源的引用写成相对路径不是更好一些么   
答案：  
最常见的例子就是处理css合并了，css中经常会有图片资源的路径引用，如果保留相对路径，会对css文件合并带来很多负担。有这么几种情况：

1. 代码中使用相对路径，合并后不做任何路径处理。这种情况下，有两种开发模式：
	1. 所有css在同级维护，构建中合并css，并且合并后的css也是同级目录。优点是不依赖工具，简单直观。缺点是不能把css和对应的html、js维护在一起，而且项目变大之后一个目录下都是css文件，又不能分二级，很恶心。
	- 所有css中写图片路径的时候，都是写那个合并后文件的相对路径。优点是css可以分级，但是写资源地址要时刻想着是在另外一个文件中使用的，这和写绝对路径有什么分别？而且IDE不友好，很多IDE会报错，别小看这个，很多程序员都是神经质，烦。
- 代码中使用相对路径，合并后根据合并后生成的文件的位置做相对路径计算。解决了1.2中的问题，通过工具重新计算相对路径。缺点是同一个文件只能被合并，不能被其他方式复用，否则会带来相对路径不一致问题。而且这都用上工具了，为啥不直接转成绝对路径。
- 代码中使用相对路径，合并后替换成绝对路径。先说缺点，依赖工具，没了。然后说说优点：
	1. 开发中使用相对路径，各种直观与友好
	- 没有规范，组件任意移植，部署路径都能正确
	- 目录任意分级，可以实现完全的组件化/模块化开发
	- 有些时候，我们可能需要把css的文件嵌入到js中，通过js动态插入到页面上，或者嵌入到html的style标签中使用，转换成绝对路径永远不用担心资源找不到的情况
	- combo随便，还是因为资源定位都是绝对路径。
	
js也有相同问题，当你在js中想要通过逻辑加载一个图片、加载一个css文件，加载其他js文件的时候，使用绝对路径可以让这个js无论在哪个页面，无论在哪一级路径下都能正确运行，有百利而无一害。（其实路径会很长，算是一害）。

有了绝对路径，资源的合并、复用、移动才能不被运行时的文档路径限制。我觉得，绝对路径才叫资源定位，才是真实的完整的定位信息，相对路径更像是一种“变量”，它使得同一段代码在不同的路径下执行会有可能发生定位错误。

其实前端页面也是一种GUI软件，传统的桌面软件，所有程序资源都部署（安装）在客户端，所以从来没有在资源上遇到过想前端的这种的定位概念。前端程序资源是部署在其他设备上的，通过运行时加载到客户端来执行，这种程序资源部署上的差异我觉得正是前端工程与GUI软件工程的最大区别，几乎所有前端开发、维护、模块化、性能优化等特殊的工程问题都是围绕着这个差异点产生的。 

##前端工程与性能优化
###性能优化原则及分类
按照优化方向分类:
![](./image/性能优化分类.png)
###静态资源版本更新与缓存
缓存利用 分类中保留了 添加Expires头 和 配置ETag 两项。或许有些人会质疑，明明这两项只要配置了服务器的相关选项就可以实现，为什么说它们难以解决呢？确实，开启这两项很容易，但开启了缓存后，我们的项目就开始面临另一个挑战： 如何更新这些缓存？

关于“添加Expires头”所说的原则一样——修订文件名。即：**最有效的解决方案是修改其所有链接，这样，全新的请求将从原始服务器下载最新的内容。**   
思路没错，但要怎么改变链接呢？变成什么样的链接才能有效更新缓存，又能最大限度避免那些没有修改过的文件缓存不失效呢？

使用构建信息（时间戳、版本号等）作为静态资源更新标记会导致每次构建发布后所有静态资源都被迫更新，浏览器缓存利用率降低，给性能带来伤害。此外，采用添加query的方式来清除缓存还有一个弊端，就是 `覆盖式发布` 的上线问题。

对于静态资源缓存更新的问题，目前来说最优方案就是 `基于文件内容的hash版本冗余机制` 了。也就是说，我们希望项目源码是这么写的：

	<script type="text/javascript" src="a.js"></script>
发布后代码变成

	<script type="text/javascript" src="a_8244e91.js"></script>
也就是a.js发布出来后被修改了文件名，产生一个新文件，并不是覆盖已有文件。其中”_82244e91”这串字符是根据a.js的文件内容进行hash运算得到的，只有文件内容发生变化了才会有更改。由于将文件发布为带有hash的新文件，而不是同名文件覆盖，因此不会出现上述说的那些问题。同时，这么做还有其他的好处：

1. 上线的a.js不是同名文件覆盖，而是文件名+hash的冗余，所以可以先上线静态资源，再上线html页面，不存在间隙问题；
- 遇到问题回滚版本的时候，无需回滚a.js，只须回滚页面即可；
- 由于静态资源版本号是文件内容的hash，因此所有静态资源可以开启永久强缓存，只有更新了内容的文件才会缓存失效，缓存利用率大增；


`以文件内容的hash值为依据生产新文件的非覆盖式发布策略是解决静态资源缓存更新最有效的手段。`

虽然这种方案是相比之下最完美的解决方案，但它无法通过手工的形式来维护，因为要依靠手工的形式来计算和替换hash值，并生成相应的文件，将是一项非常繁琐且容易出错的工作，因此我们需要借助工具来处理。

考虑这样的例子：
![](./image/文件覆盖hash.png)

由于我们的资源版本号是通过对文件内容进行hash运算得到，如上图所示，index.html中引用的a.css文件的内容其实也包含了a.png的hash运算结果，因此我们在修改index.html中a.css的引用时，不能直接计算a.css的内容hash，而是要先计算出a.png的内容hash，替换a.css中的引用，得到了a.css的最终内容，再做hash运算，最后替换index.html中的引用。

计算index.html中引用的a.css文件的url过程：

1. 压缩a.png后计算其内容的md5值
2. 将a.png的md5写入a.css，再压缩a.css，计算其内容的md5值
3. 将a.css的md5值写入到index.html中

在解决了基于内容hash的版本更新问题之后，我们可以将所有前端静态资源开启永久强缓存，每次版本发布都可以首先让静态资源全量上线，再进一步上线模板或者页面文件，再也不用担心各种缓存和时间间隙的问题了！

###静态资源管理与模块化框架
事实上，使用工具在线下进行静态资源合并是无法解决资源按需加载的问题的。如果解决不了按需加载，则必会导致资源的冗余；此外，线下通过工具实现的资源合并通常会使得资源加载和使用的分离，比如在页面头部或配置文件中写资源引用及合并信息，而用到这些资源的html组件写在了页面其他地方，这种书写方式在工程上非常容易引起维护不同步的问题，导致使用资源的代码删除了，引用资源的代码却还在的情况。因此，在工业上要实现资源合并至少要满足如下需求：

1. 确实能减少HTTP请求，这是基本要求（合并）
- 在使用资源的地方引用资源（就近依赖），不使用不加载（按需）
- 虽然资源引用不是集中书写的，但资源引用的代码最终还能出现在页面头部（css）或尾部（js）
- 能够避免重复加载资源（去重）

将以上要求综合考虑，不难发现，单纯依靠前端技术或者工具处理是很难达到这些理想要求的。

接下来我会讲述一种新的模板架构设计，用以实现前面说到那些性能优化原则，同时满足工程开发和维护的需要，这种架构设计的核心思想就是：

`基于依赖关系表的静态资源管理系统与模块化框架设计`

考虑一段这样的页面代码：

	<html>
	<head>
	    <title>page</title>
	    <link rel="stylesheet" type="text/css" href="a.css"/>
	    <link rel="stylesheet" type="text/css" href="b.css"/>
	    <link rel="stylesheet" type="text/css" href="c.css"/>
	</head>
	<body>
	    <div> content of module a </div>
	    <div> content of module b </div>
	    <div> content of module c </div>
	</body>
	</html>
根据资源合并需求中的第二项，我们希望资源引用与使用能尽量靠近，这样将来维护起来会更容易一些，因此，理想的源码是：

	<html>
	<head>
	    <title>page</title>
	</head>
	<body>
	    <link rel="stylesheet" type="text/css" href="a.css"/>
	    <div> content of module a </div>
	
	    <link rel="stylesheet" type="text/css" href="b.css"/>
	    <div> content of module b </div>
	
	    <link rel="stylesheet" type="text/css" href="c.css"/>
	    <div> content of module c </div>
	</body>
	</html>
当然，把这样的页面直接送达给浏览器用户是会有严重的页面闪烁问题的，所以我们实际上仍然希望最终页面输出的结果还是如最开始的截图一样，将css放在头部输出。这就意味着，页面结构需要有一些调整，并且有能力收集资源加载需求，那么我们考虑一下这样的源码（以php为例）：

	<html>
	<head>
	    <title>page</title>
	    <!--[ CSS LINKS PLACEHOLDER ]-->
	</head>
	<body>
	    <?php require_static('a.css'); ?>
	    <div> content of module a </div>
	
	    <?php require_static('b.css'); ?>
	    <div> content of module b </div>
	
	    <?php require_static('c.css'); ?>
	    <div> content of module c </div>
	</body>
	</html>
在页面的头部插入一个html注释 \<!--[CSS LINKS PLACEHOLDER]--> 作为占位，而将原来字面书写的资源引用改成模板接口 require_static 调用，该接口负责收集页面所需资源。

require_static接口实现非常简单，就是准备一个数组，收集资源引用，并且可以去重。最后在页面输出的前一刻，我们将require_static在运行时收集到的 a.css、b.css、c.css 三个资源拼接成html标签，替换掉注释占位 \<!--[CSS LINKS PLACEHOLDER]-->，从而得到我们需要的页面结构。

经过实践总结，可以发现模板层面只要实现三个开发接口，就可以比较完美的实现目前遗留的大部分性能优化原则，这三个接口分别是：

- require_static(res_id)：收集资源加载需求的接口，参数是静态资源id。
- load_widget(wiget_id)：加载拆分成小组件模板的接口。你可以叫它为widget、component或者pagelet之类的。总之，我们需要一个接口把一个大的页面模板拆分成一个个的小部分来维护，最后在原来的页面中以组件为单位来加载这些小部件。
- script(code)：收集写在模板中的js脚本，使之出现的页面底部，从而实现性能优化原则中的 将js放在页面底部 原则。

实现了这些接口之后，一个重构后的模板页面的源代码可能看起来就是这样的了：

	<html>
	<head>
	    <title>page</title>
	    <?php require_static('jquery.js'); ?>
	    <?php require_static('bootstrap.css'); ?>
	    <?php require_static('bootstrap.js'); ?>
	    <!--[ CSS LINKS PLACEHOLDER ]-->
	</head>
	<body>
	    <?php load_widget('a'); ?>
	    <?php load_widget('b'); ?>
	    <?php load_widget('c'); ?>
	    <!--[ SCRIPTS PLACEHOLDER ]-->
	</body>
	</html>
而最终在模板解析的过程中，资源收集与去重、页面script收集、占位符替换操作，最终从服务端发送出来的html代码为：

	<html>
	<head>
	    <title>page</title>
	    <link rel="stylesheet" type="text/css" href="bootstrap.css"/>
	    <link rel="stylesheet" type="text/css" href="a.css"/>
	    <link rel="stylesheet" type="text/css" href="b.css"/>
	    <link rel="stylesheet" type="text/css" href="c.css"/>
	</head>
	<body>
	    <div> content of module a </div>
	    <div> content of module b </div>
	    <div> content of module c </div>
	    <script type="text/javascript" src="jquery.js"></script>
	    <script type="text/javascript" src="bootstrap.js"></script>
	    <script type="text/javascript" src="a.js"></script>
	    <script type="text/javascript" src="b.js"></script>
	    <script type="text/javascript" src="c.js"></script>
	</body>
	</html>
不难看出，我们目前已经实现了 按需加载，将脚本放在底部，将样式表放在头部 三项优化原则。

前面讲到静态资源在上线后需要添加hash戳作为版本标识，那么这种使用模板语言来收集的静态资源该如何实现这项功能呢？

`答案是：静态资源依赖关系表。`

考虑这样的目录结构：

	project
	    ├── widget
	    │   ├── a
	    │   │   ├── a.css
	    │   │   ├── a.js
	    │   │   └── a.php
	    │   ├── b
	    │   │   ├── b.css
	    │   │   ├── b.js
	    │   │   └── b.php
	    │   └── c
	    │       ├── c.css
	    │       ├── c.js
	    │       └── c.php
	    ├── bootstrap.css
	    ├── bootstrap.js
	    ├── index.php
    └── jquery.js
如果我们可以使用工具扫描整个project目录，然后创建一张资源表，同时记录每个资源的部署路径，得到这样的一张表：

	{
	    "res" : {
	        "widget/a/a.css" : "/widget/a/a_1688c82.css",
	        "widget/a/a.js"  : "/widget/a/a_ac3123s.js",
	        "widget/b/b.css" : "/widget/b/b_52923ed.css",
	        "widget/b/b.js"  : "/widget/b/b_a5cd123.js",
	        "widget/c/c.css" : "/widget/c/c_03cab13.css",
	        "widget/c/c.js"  : "/widget/c/c_bf0ae3f.js",
	        "jquery.js"      : "/jquery_9151577.js",
	        "bootstrap.css"  : "/bootstrap_f5ba12d.css",
	        "bootstrap.js"   : "/bootstrap_a0b3ef9.js"
	    },
	    "pkg" : {}
	}
基于这张表，我们就很容易实现 require_static(file_id)，load_widget(widget_id) 这两个模板接口了。以load_widget为例：

	function load_widget($id){
	    //从json文件中读取资源表
	    $map = load_map();
	    //查找静态资源
	    $filename = 'widget/' . $id . '/' . $id;
	    //查找js文件
	    $js = $filename . '.js';
	    if(isset($map['res'][$js])) {
	        //如果有对应的js资源，就收集起来
	        collect_js_static($map['res'][$js]);
	    }
	    //查找css文件
	    $css = $filename . '.css';
	    if(isset($map['res'][$css])) {
	        //如果有对应的css资源，就收集起来
	        collect_css_static($map['res'][$css]);
	    }
	    include $filename . '.php';
	}
利用查表来解决md5戳的问题，这样，我们的页面最终送达给用户的结果就是这样的：

	<html>
	<head>
	    <title>page</title>
	    <link rel="stylesheet" type="text/css" href="/bootstrap_f5ba12d.css"/>
	    <link rel="stylesheet" type="text/css" href="/widget/a/a_1688c82.css"/>
	    <link rel="stylesheet" type="text/css" href="/widget/b/b_52923ed.css"/>
	    <link rel="stylesheet" type="text/css" href="/widget/c/c_03cab13.css"/>
	</head>
	<body>
	    <div> content of module a </div>
	    <div> content of module b </div>
	    <div> content of module c </div>
	    <script type="text/javascript" src="/jquery_9151577.js"></script>
	    <script type="text/javascript" src="/bootstrap_a0b3ef9.js"></script>
	    <script type="text/javascript" src="/widget/a/a_ac3123s.js"></script>
	    <script type="text/javascript" src="/widget/b/b_a5cd123.js"></script>
	    <script type="text/javascript" src="/widget/c/c_bf0ae3f.js"></script>
	</body>
	</html>
接下来，我们讨论基于表的设计思想上是如何实现静态资源合并的。或许有些团队使用过combo服务，也就是我们在最终拼接生成页面资源引用的时候，并不是生成多个独立的link标签，而是将资源地址拼接成一个url路径，请求一种线上的动态资源合并服务，从而实现减少HTTP请求的需求，比如前面的例子，稍作调整即可得到这样的结果：

	<html>
	<head>
	    <title>page</title>
	    <link rel="stylesheet" type="text/css" href="/??bootstrap_f5ba12d.css,widget/a/a_1688c82.css,widget/b/b_52923ed.css,widget/c/c_03cab13.css"/>
	</head>
	<body>
	    <div> content of module a </div>
	    <div> content of module b </div>
	    <div> content of module c </div>
	    <script type="text/javascript" src="/??jquery_9151577.js,bootstrap_a0b3ef9.js,widget/a/a_ac3123s.js,widget/b/b_a5cd123.js,widget/c/c_bf0ae3f.js"></script>
	</body>
	</html>
这个 /??file1,file2,file3,… 的url请求响应就是动态combo服务提供的，它的原理很简单，就是根据url找到对应的多个文件，合并成一个文件来响应请求，并将其缓存，以加快访问速度。

这种方法很巧妙，有些服务器甚至直接集成了这类模块来方便的开启此项服务，这种做法也是大多数大型web应用的资源合并做法。但它也存在一些缺陷：

1. 浏览器有url长度限制，因此不能无限制的合并资源。
- 如果用户在网站内有公共资源的两个页面间跳转访问，由于两个页面的combo的url不一样导致用户不能利用浏览器缓存来加快对公共资源的访问速度。
- 如果combo的url中任何一个文件发生改变，都会导致整个url缓存失效，从而导致浏览器缓存利用率降低。

对于上述第二条缺陷，可以举个例子来看说明：

- 假设网站有两个页面A和B
- A页面使用了a，b，c，d四个资源
- B页面使用了a，b，e，f四个资源
- 如果使用combo服务，我们会得：
	- A页面的资源引用为：/??a,b,c,d
	- B页面的资源引用为：/??a,b,e,f
- 两个页面引用的资源是不同的url，因此浏览器会请求两个合并后的资源文件，跨页面访问没能很好的利用a、b这两个资源的缓存。

很明显，如果combo服务能聪明的知道A页面使用的资源引用为 /??a,b 和 /??c,d，而B页面使用的资源引用为 /??a,b 和 /??e,f就好了。这样当用户在访问A页面之后再访问B页面时，只需要下载B页面的第二个combo文件即可，第一个文件已经在访问A页面时缓存好了的。

基于这样的思考，我们在资源表上新增了一个字段，取名为 pkg，就是资源合并生成的新资源，表的结构会变成：

	{
	    "res" : {
	        "widget/a/a.css" : "/widget/a/a_1688c82.css",
	        "widget/a/a.js"  : "/widget/a/a_ac3123s.js",
	        "widget/b/b.css" : "/widget/b/b_52923ed.css",
	        "widget/b/b.js"  : "/widget/b/b_a5cd123.js",
	        "widget/c/c.css" : "/widget/c/c_03cab13.css",
	        "widget/c/c.js"  : "/widget/c/c_bf0ae3f.js",
	        "jquery.js"      : "/jquery_9151577.js",
	        "bootstrap.css"  : "/bootstrap_f5ba12d.css",
	        "bootstrap.js"   : "/bootstrap_a0b3ef9.js"
	    },
	    "pkg" : {
	        "p0" : {
	            "url" : "/pkg/lib_cef213d.js",
	            "has" : [ "jquery.js", "bootstrap.js" ]
	        },
	        "p1" : {
	            "url" : "/pkg/lib_afec33f.css",
	            "has" : [ "bootstrap.css" ]
	        },
	        "p2" : {
	            "url" : "/pkg/widgets_22feac1.js",
	            "has" : [
	                "widget/a/a.js",
	                "widget/b/b.js",
	                "widget/c/c.js"
	            ]
	        },
	        "p3" : {
	            "url" : "/pkg/widgets_af23ce5.css",
	            "has" : [
	                "widget/a/a.css",
	                "widget/b/b.css",
	                "widget/c/c.css"
	            ]
	        }
	    }
	}
相比之前的表，可以看到新表中多了一个pkg字段，并且记录了打包后的文件所包含的独立资源。这样，我们重新设计一下 require_static、load_widget 这两个模板接口，实现这样的逻辑：

**在查表的时候，如果一个静态资源有pkg字段，那么就去加载pkg字段所指向的打包文件，否则加载资源本身。**
比如执行require_static('bootstrap.js')，查表得知bootstrap.js被打包在了p1中，因此取出p1包的url /pkg/lib_cef213d.js，并且记录页面已加载了 jquery.js 和 bootstrap.js 两个资源。这样一来，之前的模板代码执行之后得到的html就变成了：

	<html>
	<head>
	    <title>page</title>
	    <link rel="stylesheet" type="text/css" href="/pkg/lib_afec33f.css"/>
	    <link rel="stylesheet" type="text/css" href="/pkg/widgets_af23ce5.css"/>
	</head>
	<body>
	    <div> content of module a </div>
	    <div> content of module b </div>
	    <div> content of module c </div>
	    <script type="text/javascript" src="/pkg/lib_cef213d.js"></script>
	    <script type="text/javascript" src="/pkg/widgets_22feac1.js"></script>
	</body>
	</html>
虽然这种策略请求有4个，不如combo形式的请求少，但可能在统计上是性能更好的方案。由于两个lib打包的文件修改的可能性很小，因此这两个请求的缓存利用率会非常高，每次项目发布后，用户需要重新下载的静态资源可能要比combo请求节省很多带宽。

性能优化既是一个工程问题，又是一个统计问题。优化性能时如果只关注一个页面的首次加载是很片面的。还应该考虑全站页面间跳转、项目迭代后更新资源等情况下的优化策略。
此时，我们又引入了一个新的问题：如何决定哪些文件被打包？

从经验来看，项目初期可以采用人工配置的方式来指定打包情况，比如：

	{
	    "pack" : {
	        "lib.js"      : [ "jquery.js", "bootstrap.js" ],
	        "lib.css"     : "bootstrap.css",
	        "widgets.js"  : "widget/**.js",
	        "widgets.css" : "widget/**.css"
	    }
	}
但随着系统规模的增大，人工配置会带来非常高的维护成本，此时需要一个辅助系统，通过分析线上访问日志和静态资源组合加载情况来自动生成这份配置文件，系统设计如图：

![](./image/静态资源组合加载配置表.png)

至此，我们通过基于表的静态资源管理系统和三个模板接口实现了几个重要的性能优化原则.

`拆分初始化负载` 的目标是将页面一开始加载时不需要执行的资源从所有资源中分离出来，等到需要的时候再加载。工程师通常没有耐心去区分资源的分类情况，但我们可以利用组件化框架接口来帮助工程师管理资源的使用。还是从例子开始思考，如果我们有一个js文件是用户交互后才需要加载的，会怎样呢：
	
	<html>
	<head>
	    <title>page</title>
	    <?php require_static('jquery.js'); ?>
	    <?php require_static('bootstrap.css'); ?>
	    <?php require_static('bootstrap.js'); ?>
	    <!--[ CSS LINKS PLACEHOLDER ]-->
	</head>
	<body>
	    <?php load_widget('a'); ?>
	    <?php load_widget('b'); ?>
	    <?php load_widget('c'); ?>
	
	    <?php script('start'); ?>
	    <script>
	        $(document.body).click(function(){
	            require.async('dialog.js', function(dialog){
	                dialog.show('you catch me!');
	            });
	        });
	    </script>
	    <?php script('end'); ?>
	
	    <!--[ SCRIPTS PLACEHOLDER ]-->
	</body>
	</html>
很明显，dialog.js 这个文件我们不需要在初始化的时候就加载，因此它应该在后续的交互中再加载，但文件都加了md5戳，我们如何能在浏览器环境中知道加载的url呢？

`答案就是：把静态资源表的一部分输出在页面上，供前端模块化框架加载静态资源。`

我就不多解释代码的执行过程了，大家看到完整的html输出就能理解是怎么回事了：

	<html>
	<head>
	    <title>page</title>
	    <link rel="stylesheet" type="text/css" href="/pkg/lib_afec33f.css"/>
	    <link rel="stylesheet" type="text/css" href="/pkg/widgets_af23ce5.css"/>
	</head>
	<body>
	    <div> content of module a </div>
	    <div> content of module b </div>
	    <div> content of module c </div>
	    <script type="text/javascript" src="/pkg/lib_cef213d.js"></script>
	    <script type="text/javascript" src="/pkg/widgets_22feac1.js"></script>
	    <script>
	        //将静态资源表输出在前端页面中
	        require.config({
	            res : {
	                'dialog.js' : '/dialog_fa3df03.js'
	            }
	        });
	    </script>
	    <script>
	        $(document.body).click(function(){
	            //require.async接口查表确定加载资源的url
	            require.async('dialog.js', function(dialog){
	                dialog.show('you catch me!');
	            });
	        });
	    </script>
	</body>
	</html>
dialog.js不会在页面以script src的形式输出，而是变成了资源注册，这样，当页面点击触发require.async执行的时候，async函数才会查表找到资源的url并加载它，加载完毕后触发回调函数。

到目前为止，我们又以架构的形式实现了一项优化原则（拆分初始化负载），回顾我们的优化分类表，现在仅有两项没能做到了：

优化方向	优化手段    
缓存利用	使Ajax可缓存    
页面结构	尽早刷新文档的输出    

剩下的两项优化原则要做到并不容易，真正可缓存的Ajax在现实开发中比较少见，而 `尽早刷新文档的输出` 原则facebook在2010年的velocity上提到过，就是BigPipe技术。当时facebook团队还讲到了Quickling和PageCache两项技术，其中的PageCache算是比较彻底的实现Ajax可缓存的优化原则了。

##如何进行前端自动化测试？
>前端是一种特殊的GUI软件   
API测试方法论在测试GUI时并不能解决所有问题。

前端有那么一小部分代码是可以用API测试保证质量的，但前端项目中的绝大多数代码是GUI界面，前端测试应该向传统GUI测试方法论需求解决方案：[GUI软件测试_百度百科
](http://baike.baidu.com/view/5131653.htm)

GUI软件测试的研究还处于初级阶段：很多问题还没有解决，GUI软件测试依然需要较高人工成本，目前的技术还不能满足保证软件质量的实际需求。

与不带GUI的软件相比，GUI软件具有很多特性。

1. GUI软件接收到的输入是作用于GUI上的各种事件（Event）；
- GUI软件所能接受的输入受到GUI本身结构和状态的限制。GUI本身具有特定的层次结构，同时也具有自身的状态。GUI软件运行中，用户需要根据这些信息来进行软件操作；
- GUI软件的输出形式多样，可能是图形界面上的变化、图像、文字或者若干个事件；
- 软件的运行结果不仅仅决定于当前时刻的输入，与软件的初始状态和操作历史（之前的用户操作）都有关系；
- GUI软件运行对操作系统依赖性很强。GUI软件运行过程中经常会调用操作系统的功能，这使得外部设备的状态，操作系统的状态都会对GUI软件的运行产生影响。GUI软件与操作系统之间的界限变得模糊，许多功能是通过操作系统的接口函数与软件代码的交互实现的。

GUI测试的成本非常高，而前端这种特殊的GUI软件，具有天生的快速迭代特征，这使得case维护成本也变得非常高，经常跟不上迭代速度。

一个标准的互联网应用产品的前端部分，我粗略估计大概有20%的业务基础代码比较稳定，比如通用组件、通用算法和数据模块等，可以针对这些建立复杂一些的API和GUI测试用例来保证质量。剩下80%的部分不是很稳定，每天都在迭代，针对他们维护case的成本非常高。目前业界中号称做了自动化测试的项目，也大多是在做那稳定的20%。

**原则：以最低的成本建立和维护自动化测试用例。**

页面差异监控的目的是方便的通知人肉回归范围，这并非测试方案，而是一种辅助测试的手段。

###个人认为一般`前端自动化测试`大致包括

- 类库单元测试自动化
- UI组件测试自动化

####类库单元测试自动化
基本思路是让不同的浏览器可以自动根据指令跑一些JS函数, 结果与预期比对后返回是否通过case测试标志.

其中一般有两种实现方式：

其一：

1. 打开目标浏览器，运行测试框架站点
2. 测试框架站点通过ajax 轮询、websocket 等方式，将待测 js 的 case 在浏览器内运行（通过eval 、createElement("script") 等方式）
3. 比对测试结果，将结果 post 到远端远
4. 端接受测试结果远端等待所有浏览器返回结果完成
5. marge 所有浏览器数据显示最终通过与否结果。

	这种方式弊端：
	- 人工开启一次所有浏览器
	- 需要排队测试，浏览器只能一次运行完一组测试后才能再运行下一组
	- 如果中间某testcase导致浏览器异常，返回结果将缺失，需要人工去服务器上检查下浏览器状
	态
	
	好处：   
	
	可以覆盖所有想覆盖到的浏览器

另一种方式：

1. 将常用浏览器内核放进一个或多个相互有关联的进程内
2. 用例通过系统消息发送到各个包装的内核中
3. 每次开启一个新内核进程运行JS用例
4. 用例结果发送给包装进程
5. 包装进程汇集所有用例结果后post到远端保存
6. 包装进程连带内核进程一起退出

	优点：
	- 无序人工开启一次浏览器
	- 独立进程运行，无需排队
	- 不怕内核异常，异常后包装进程可以直接恢复内核或者通知测试失败
	
	缺点：
	- 前端实现太困难，需要C++开发
	- 无法覆盖到所有浏览器
	- 常用内核覆盖更新劳心劳力
	
####UI组件测试自动化
因为 UI 涉及可视化内容，需要实现不同 testcase 的自动化界面操作，常见的如，单双击、拖拽、自动表单内容填写等。

一般用 Selenium 来录操作后执行或者使用 phantomjs 等工具写模拟操作脚本来实现

这类东西一般就不太指望能跨全平台了，一个浏览器能跑通就不错了。

#####基于 `phantomjs` 的自动化测试
它主要靠js脚本来模拟操作，一般流程是写代码写代码写代码

1. open 某个 
2. url监听 onload 事件
3. 事件完成后调用 sendEvent 之类的 api 去点击某个 DOM 元素所在 point
4. 触发交互
5. 根据 UI 交互情况 延时 setTimeout （规避惰加载组件点不到的情况）继续 sendEvent 之类的交互
6. 最后调用截图 api 发送操作结果到远端用于人工（或机器）审核 UI 结果是否正常。

##前端工程与模块化框架
模块化框架是前端工程中的最为核心的部分 。

前端模块化框架肩负着 **模块管理**、**资源加载** 两项重要的功能，这两项功能与工具、性能、业务、部署等工程环节都有着非常紧密的联系。因此，模块化框架的设计应该最高优先级考虑工程需要。
###再谈 SeaJS 与 RequireJS 的差异
模块化框架在工程方面的缺点：

1. requirejs和seajs二者在加载上都有缺陷，就是模块的依赖要等到模块加载完成后，通过静态分析（seajs）或者deps参数（requirejs）来获取，这就为 合并请求 和 按需加载 带来了实现上的矛盾：
	- 要么放弃按需加载，把所有js合成一个文件，从而满足请求合并（两个框架的官方demo都有这样的例子）；
	- 要么放弃请求合并，请求独立的模块文件，从而满足按需加载。
2. AMD规范在执行callback的时候，要初始化所有依赖的模块，而CMD只有执行到require的时候才初始化模块。所以用AMD实现某种if-else逻辑分支加载不同的模块的时候，就会比较麻烦了。考虑这种情况：

		//AMD for SPA
		require(['page/index', 'page/detail'], function(index, detail){
		    //在执行回调之前，index和detail模块的factory均执行过了
		    switch(location.hash){
		        case '#index':
		            index();
		        break;
		        case '#detail':
		            detail();
		        break;
		    }
		});
在执行回调之前，已经同时执行了index和detail模块的factory，而CMD只有执行到require才会调用对应模块的factory。这种差别带来的不仅仅是性能上的差异，也可能为开发增加一点小麻烦，比如不方便实现换肤功能，factory注意不要直接操作dom等。当然，我们可以多层嵌套require来解决这个问题，但又会引起模块请求串行的问题。

**结论**：以纯前端方式实现模块化框架 不能 同时满足 `按需加载`，`请求合并` 和 `依赖管理` 三个需求。   
导致这个问题的根本原因是 `纯前端方式只能在运行时分析依赖关系`。

###解决模块化管理的新思路
由于根本问题出在 `运行时分析依赖`，因此新思路的策略很简单：不在运行时分析依赖。这就要借助 `构建工具` 做线下分析了，其基本原理就是：

>利用构建工具在线下进行 `模块依赖分析`，然后把依赖关系数据写入到构建结果中，并调用模块化框架的 `依赖关系声明接口` ，实现模块管理、请求合并以及按需加载等功能。
举个例子，假设我们有一个这样的工程：

	project
	  ├ lib
	  │  └ xmd.js    #模块化框架
	  ├ mods         #模块目录
	  │  ├ a.js
	  │  ├ b.js
	  │  ├ c.js
	  │  ├ d.js
	  │  └ e.js
	  └ index.html   #入口页面
工程中，index.html 的源码内容为：

	<!doctype html>
	...
	<script src="lib/xmd.js"></script>   <!-- 模块化框架 -->
	<script>
	    //等待构建工具生成数据替换 `__FRAMEWORK_CONFIG__' 变量
	    require.config(__FRAMEWORK_CONFIG__);
	</script>
	<script>
	    //用户代码，异步加载模块
	    require.async(['a', 'e'], function(a, e){
	        //do something with a and e.
	    });
	</script>
	...
工程中，mods/a.js 的源码内容为（采用类似CMD的书写规范）：

	define('a', function(require, exports, module){
	    console.log('a.init');
	    var b = require('b');
	    var c = require('c');
	    exports.run = function(){
	        //do something with b and c.
	        console.log('a.run');
	    };
	});
###具体实现过程
1. 用工具在线下对工程文件进行扫描，得到依赖关系表：

		{
		    "a" : [ "b", "c" ],
		    "b" : [ "d" ]
		}
- 工具把依赖表构建到页面或者脚本中，并调用模块化框架的配置接口，index.html的构建结果为：

		<!doctype html>
		...
		<script src="lib/xmd.js"></script>   <!-- 模块化框架 -->
		<script>
		    //构建工具生成的依赖数据
		    require.config({
		        "deps" : {
		            "a" : [ "b", "c" ],
		            "b" : [ "d" ]
		        }
		    });
		</script>
		<script>
		    //用户代码，异步加载模块
		    require.async(['a', 'e'], function(a, e){
		        //do something with a and e.
		    });
		</script>
- 模块化框架根据依赖表加载资源，比如上述例子，入口需要加载a、e两个模块，查表得知完整依赖关系，配合combo服务，可以发起一个合并后的请求：    
http://www.example.com/??d.js,b.js,c.js,a.js,e.js

####先来看一下这种方案的优点
1. 采用类似CMD的书写规范（同步require函数声明依赖），可以在执行到require语句的时候才调用模块的factory。
- 虽然采用CMD书写规范，但放弃了运行时分析依赖，改成工具输出依赖表，因此 依赖分析完成后可以压缩掉require关键字
- 框架并没有严格依赖工具，它只是约定了一种数据结构。不使用工具，人工维护 require.config({...}) 相关的数据也是可以的。对于小项目，文件全部合并的情况，更加不需要deps表了，只要在入口的require.async调用之前加载所有模块化的文件，依赖关系无需额外维护
- 构建工具设计非常简单，而且可靠。工作就是扫描模块文件目录，得到依赖表，JSON序列化之后插入到构建代码中
- 由于框架预先知道所有模块的依赖关系，因此可以借助combo服务实现`请求合并`，而不用等到一级模块加载完成才能知道后续的依赖关系。
- 如果构建工具可以自动包装define函数，那么整个系统开发起来会感觉跟nodejs非常接近，比较舒服。

####再来讨论一下这种方案的缺点：
由于采用require函数作为依赖标记，因此如果需要变量方式require，需要额外声明，这个时候可以实现兼容AMD规范写法，比如

	define('a', ['b', 'c'], function(require, exports, module){
	    console.log('a.init');
	    var name = isIE ? 'b' : 'c';
	    var mod = require(name);
	    exports.run = function(){
	        //do something with mod.
	        console.log('a.run');
	    };
	})
只要工具把define函数中的 deps 参数，或者factory内的require都作为依赖声明标记来识别，这样工程性就比较完备了。

但不管怎样， `线下分析始终依靠了字面量信息`，所以开发上可能会有一定的局限性，但总的来说瑕不掩瑜。

###讨论
对于特别大的工程，并不是一个完整的表，而是要有“命名空间”的概念，将表拆分成多个命名空间。工具负责维护和提取每个命名空间下的表信息。这条路可以继续探索下去，相信以表为媒介，连接框架和工具以及规范，是比较合理的一个出路。

大家的方案都差不多，目前来看有以下几种：

1. 大家误以为的 seajs 方式：什么都动态分析、加载。（这种方式其实我们只用在开发调试时）
- 用工具生成 config 配置表的方式。类似 YUI、KISSY 采用的方式，有利有弊，配置表的维护并非那么轻松，特别是在阿里目前的模板技术背景，以及考虑 cms 区域的情况下。
- 用工具提取信息到文件本身的方式，线下打包好。Arale 在支付宝的实践，通过 spm 来完成，目前实践下来还可以，但依旧存在一些小痛。
- 用工具提取信息到文件本身，然后通过服务端（CDN源服务器）来实现自动打包的方式。目前阿里国际站在尝试，YAHOO 后来有部分业务线也走向了这种方式。支付宝还在考察观望。

`阿里`把模块拆得这么碎，然后用看上去很怪异的方式，在nginx那边搞combiner来合并，然后也正是为此，可能js会有乱序，必须晚期依赖。

在`百度`，对于大型系统，我们都不是整站构建的，而是按业务拆成了很多个子系统，每个产品会产生一张资源表，跨业务的依赖会引入对应产品库的表，每个业务子系统是独立构建上线的。举个例子：

	site(站点)
	  ├ common.git     #公共子系统模块
	  ├ user.git       #用户子系统模块
	  ├ message.git    #消息子系统模块
	  ├ ...
每个子系统独立构建，并产生独立的表，线上部署的大致效果为：

	www
	  ├ map               #表目录
	  │  ├ common.json    #公共子系统静态资源关系表
	  │  ├ user.json      #用户子系统静态资源关系表
	  │  ├ message.json   #消息子系统静态资源关系表
	  │  ├ ...
	  ├  template         #模板目录
	  │  ├ common         #公共子系统模板
	  │  ├ user           #用户子系统模板
	  │  ├ message        #消息子系统模板
	  │  ├ ...
每个子系统的静态资源id结构为： 系统名:资源id，比如common系统下的jquery代码，其id为 common:lib/jquery/jquery-2.0.2.js，所有的依赖关系可以记录在模板或模板所引用的js中的，模板中提供了静态资源管理和加载的接口，比如user子系统中希望使用message系统下的资源，其代码为（在user.git下的widget/user-info/user-info.php）：

	<?php import('common:lib/jquery/jquery-2.0.2.js');  ?>
	<?php import('user:widget/user-info/user-info.js');  ?>
	<?php import('user:widget/user-info/user-info.css');  ?>
	blablabla
模板中的import函数，会在运行时读取资源表来实现静态资源按需，资源表中也记录了子系统内代码的合并情况，可以在模板运行期间计算静态资源的最优组合（带宽、请求数等）

每个系统独立构建，只有运行时的交叉引用，不会出现整站构建的情况.

模块化框架，作为前端工程的 **重中之重**，是应该被反复锤炼和完善的，而且以我现在的认知来看，模块化框架非常有必要 每个团队根据自己的业务形态单独设计和实现一套。为cms模板服务的模块化框架、为spa服务的模块化框架，为小型项目服务的模块化框架、为大型系统服务的模块化框架，都有各自不同的问题域，实现上会有很大差异。由于模块管理本身逻辑很简洁，所以自己实现的收益是大的。

**前端工程的核心是模块化框架，实践总结的是，模块化框架会关联工具、规范、部署等问题的，所以，原则上讲，选择了一种模块化框架，就要选择其配套的工具及规范，类似选了seajs，就要接受spm，接受了require.js，要接受它的r.js一样。**当然也可以自己DIY工具，但有些规范基本上是天生定义好了的。

根据实践总结，`合理的打包方案`应该是：

1. `经常修改的文件` 与 `极少修改的文件` 分开打包，可有效提升缓存利用率
- `多页面共用的文件` 与 `极少页面会用的文件` 分开打包，可有效提升用户跨页面浏览的缓存命中率
- `支持按需加载的动态合并` 可有效提升SPA应用的展现性能

这三条原则，本身也有一些矛盾的地方，最终确定的打包方案应该是根据业务权衡的。当然，我可以补充一条：  
当且仅当业务规模很小，缓存命中、按需加载收益不明显时，aio的方式才因为没那么矬而不被察觉其劣势。

aio是一条极端的路线，让多页面的站点缓存很鸡肋了，而让单页面的应用又失去了按需加载。从amd/cmd最开始的动态加载到后来按照规范实现服务器端合并再到现在browserify的一刀切，虽然实践不足，但是经过几个项目也很认可具体业务具体分析，现实往往比理想差，而且差很多。
与本文关系不大的是，browserify的想法貌似很大，尝试为很多node的包做浏览器的兼容，我感觉这个唯一的意义就是让node的包可以直接运行在浏览器，但是好像真正对于生产的意义还有待观察。

问题是这样的包到底有哪些？好像实际业务中基本没有。曾经有一些框架说“让js在前后端都能跑”也是扯淡，看过某些所谓前后端能跑的js，其实都是这样的代码结构：

	if(runAtServer){
	    //do something in server
	} else {
	    //do something in browser
	}
是的，输出到前端的代码携带了一坨不需要的逻辑分支，这对于要求低带宽的前端来说好矬逼，而且很容易暴露server端的敏感信息。

新人的学习过程，用发展的眼光看待两种选择，历程可能是：

1. 选择以框架为起点：读框架 → 补基础 → 理解框架 → 运用基础+框架设计思想
- 选择以基础为起点：学基础 → 运用觉得锉 → 阅读框架 → 运用基础+框架设计思想

比较简单策略来更新localstorage缓存的 js 和 css 模块化资源，基于版本，简单粗暴。因为我们不是非常信任移动端localstorage的可靠性，所以目前用的缓存策略仅比Cache-Control/Expires效果好那么一点而已，足够可靠，对于localstorage则是能用就用。原来在百度实现的会稍微复杂一些，精细到单文件级别。

###模块化框架

####1. 模块接口导入导出
一般模块化框架或方案（requirejs/seajs/nodejs）遵循的是CommonJS的模块内部 上下文规范，也就是模块内上下文中的 require 函数和 exports 对象，以及 modules.exports 属性。

在ES6中，给出了 import 和 export 关键字，写法可以在网上查到，这里不举例了。

####2. 模块定义
现阶段模块化框架（requirejs/seajs）为了在浏览器中实现模块定义，提供模块接口导入导出的方式，还须提供模块定义函数 define(id, deps, factory) ，模块代码就写在factory参数的作用域中，并能实现模块接口导入导出的管理。

同样，在ES6中，也给出了 module 关键字，用于定义模块。

####3. 模块加载
在浏览器端，模块化框架为了解决依赖问题，需要实现按依赖异步加载模块资源，加载完成后才能执行对应的模块代码，这是在浏览器中实现模块化所必须面对的现实问题，其实模块加载和模块化的核心部分关系并不大，它可以被独立实现。seajs和requirejs在模块加载上实现并不一致，连接口名称都不同，由此可见模块加载的特殊性。

个人觉得，模块加载是前端工程化的重要组成部分
以上，就是模块化框架的全部内容了，总结为一幅图大概是：

![](./image/模块化框架.png)

模块化核心部分（导入导出、定义）代码其实很少，写一个也就4、50行而已，半小时手起刀落应该就能搞定，真正重点是模块加载。

**模块加载有这么几个痛点：**

1. 按需加载：就是依赖什么就加载什么，别搞aio（all-in-one）。
- 并行加载：不搞aio的打包，但也不能串行加载，有的框架要加载完才知道依赖，这样就串行请求了，工程上根本用不了。
- 请求合并：在HTTP1.1时代，虽然没有明显的证据表明请求合并比不合并能快多少，但是大家确实心里有阴影，不然也不会有all-in-one了，请求合并这件事还挺刚需的。

模块化框架做的好不好，`加载是重点`，以上三条，则是重点中的重点。

fis的核心功能，其实不是什么压缩、校验这些基础功能，而是扫描所有项目代码，识别其中的依赖关系，并整理出一个 map.json 的资源依赖关系表，里面记录了资源的id、url和依赖关系.

####问题：关于利用工具抽取依赖关系的问题
有资源表和基于表的资源管理框架可以很容易的将开发和部署以及性能优化分离开，表的结构比较简单，可以由工具生成，这样工具部分就有大部分功能可以在不同的架构中通用了，前端渲染架构把表注入到前端页面，配合模块加载器加载资源，后端渲染架构把表部署到模板服务器配合模板引擎实现组件化加载，深耕资源管理框架（在前端就是模块加载器，在后端就是模板的资源引用扩展）可以获得更多的性能收益，而且优化过程对开发透明，同一套构建工具可以适应不同的前后端方案，黑盒部分很小，这是我所推崇的做法。

####问题：关于fisp的quickling的问题
其实facebook当年提出了三个技术概念：

1. pagelet：页面局部，用于划分页面上的一些区域，它属于一种开发概念，并不是技术实现；pagelet是下面二者的基础。
2. bigpipe：以chunk的方式把pagelet分片输出，目的是在后端读取数据渲染模板的时候可以以pagelet为单位并行异步获取数据，然后以js片段的形式flush输出，这个需要对php进行改造，支持异步
3. quickling：页面间跳转的时候，不是全刷，而是以pagelet为单位，局部替换。有些人好像也管它叫pjax。

简单来说，`pagelet提供了一种单位，bigpipe解决了页面首次加载的展现性能问题，quickling解决了页面间切换的性能和体验问题。`

当然，三者配合使用效果最好，但bigpipe和quickling并不一定是捆绑的，二者都可以单独实现。只实现bigpipe，效果是渲染速度快了，流水线加工页面，没有quickling只不过页面跳转是全刷而已。单纯实现quickling而不做bigpipe，这样虽然没有首次访问页面的加速效果，但是页面间切换效果很不错，是异步局刷的。

这个方案还根据google的移动端性能优化最佳实践 https://developers.google.com/speed/docs/insights/mobile 做了首屏CSS内嵌的优化，提供了一个 {% ATF %} 首屏位置标签，把这个标签写到模板中，标签以前的资源会内嵌，标签以后的资源会link加载，以实现google给出的首屏优化策略。

**前端作为一种GUI软件，我还是觉得应该以组件为单位进行分治，每个组件内维护自己的HTML/JS/CSS/图片等程序资源，是最小的开发单位。这就要求每个工程师都具备完整的前端基本技能**

**组件化开发其目的是 分而治之 ，是为了更好的进行系统拆分和工程维护，它并不是为了技术上的复用。复用在前端这种定制化程度极高的软件开发领域意义并不是非常大，但分治却是前端工程必须的。**

**组件对外提供的接口应该是怎么样的？如何调用？**

这要取决于你使用什么渲染模型和什么组件化框架。

1. `后端渲染模型`  
就是在服务端拼装模板生成html，前端只是负责增加交互能力
这种情况下组件一般对外暴露的是模板层面的组件调用接口和前端层面组件事件派发。后端渲染模型下，页面在服务端拼装，到达前端的时候已经是完整的HTML内容了，HTML先呈现，然后js才添加事件实现复杂的交互能力，这时候我们通常会设计一种事件中心的机制来解决组件间通信问题，所以一般情况下组件暴露的只是模板层面的引用和自身所能派发的事件列表。

2. `前端渲染模型`   
通常是webapp模式，由js全权负责拼装html。
由于是js控制的界面构建，整个过程是程序可以干预的，因此js会对组件进行封装，并管理其生命周期，也就有了基本的创建实例(init、create、new)、添加到dom树（render）、视图更新（update）、实例销毁（destroy）等接口，以及其他特定的组件方法。

现在有了很多MVVM框架，是组件化开发的利器，所以很多人会选择一个这样的框架，比如 vuejs（推荐）、react、angularjs等，由它们负责管理组件的生命周期，然后通过驱动数据解决组件状态改变和通信问题，最终面对的是数据操作，不需要太多接口.

每个页面并不是孤岛资源，它们还会依赖其他组件，组件与组件之间可能还有共享的基础库依赖。

##模块化开发
通过 **组装模块** 得到⼀一个完整的应⽤。

模块化开发

- 模块是`可组合`、`可分解`和`更换`的单元- 模块具有⼀一定的`独⽴性`。- 将模块所需的js、css、 图⽚片、模板`维护在⼀起`

**保证模块的：独⽴立性、可组装性、可更换性；以最自然的方式写码**
- 一个模块一个目录（将来维护，在这一个目录下管理就ok了）
- 像写nodejs⼀一样写js模块 
- 将模板嵌⼊入到js中 
- css只关⼼心模块内样式 
- css也有依赖关系
- 相对路径引用资源
- 引用模块即加载所有资源

<br>
参考文档：   
https://github.com/fouber/blog   
性能优化:    
http://www.infoq.com/cn/articles/front-end-engineering-and-performance-optimization-part1    
http://www.infoq.com/cn/articles/front-end-engineering-and-performance-optimization-part2   
再谈 SeaJS 与 RequireJS 的差异
http://div.io/topic/430      
前端模块化开发那点历史
https://github.com/seajs/seajs/issues/588
<hr>